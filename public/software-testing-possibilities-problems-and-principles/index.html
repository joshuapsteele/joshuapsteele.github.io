<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Software Testing: Possibilities, Problems, and Principles | Joshua P. Steele</title>
<meta name=keywords content="software,testing"><meta name=description content="Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.



Software Testing, Our Field’s Least-Sexy Superpower
Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!"><meta name=author content="joshuapsteele"><link rel=canonical href=https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/><link crossorigin=anonymous href=/assets/css/stylesheet.1d3078ba3408f1410cbc7d07f412ada5ed26271bb27c7c601a7d46da382b440c.css integrity="sha256-HTB4ujQI8UEMvH0H9BKtpe0mJxuyfHxgGn1G2jgrRAw=" rel="preload stylesheet" as=style><link rel=icon href=https://joshuapsteele.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://joshuapsteele.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://joshuapsteele.com/favicon-32x32.png><link rel=apple-touch-icon href=https://joshuapsteele.com/apple-touch-icon.png><link rel=mask-icon href=https://joshuapsteele.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://joshuapsteele.com/css/extended/custom.min.29813e946f92d51ad1f386ece6488324ef1119fbc7e73c5677ff6ccb8f4dfd82.css integrity="sha256-KYE+lG+S1RrR84bs5kiDJO8RGfvH5zxWd/9sy49N/YI="><link rel=preload href=https://joshuapsteele.com/images/default-social.png as=image><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//cdn.jsdelivr.net><meta property="og:type" content="article"><meta property="og:url" content="https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/"><meta property="og:title" content="Software Testing: Possibilities, Problems, and Principles | Joshua P. Steele"><meta property="og:description" content="Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.



Software Testing, Our Field’s Least-Sexy Superpower
Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!"><meta property="og:image" content="https://joshuapsteele.com/images/default-social.png"><meta property="og:image:alt" content="Joshua P. Steele"><meta property="og:site_name" content="Joshua P. Steele"><meta name=twitter:card content="summary_large_image"><meta name=twitter:url content="https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/"><meta name=twitter:title content="Software Testing: Possibilities, Problems, and Principles | Joshua P. Steele"><meta name=twitter:description content="Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.



Software Testing, Our Field’s Least-Sexy Superpower
Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!"><meta name=twitter:image content="https://joshuapsteele.com/images/default-social.png"><meta name=twitter:image:alt content="Joshua P. Steele"><meta property="article:published_time" content="2022-12-21T21:08:05Z"><meta property="article:modified_time" content="2025-03-31T16:22:26-0400"><meta property="article:tag" content="software"><meta property="article:tag" content="testing"><meta property="og:url" content="https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/"><meta property="og:site_name" content="Joshua P. Steele"><meta property="og:title" content="Software Testing: Possibilities, Problems, and Principles"><meta property="og:description" content="Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.
Software Testing, Our Field’s Least-Sexy Superpower Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!"><meta property="og:locale" content="en-US"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-12-21T21:08:05+00:00"><meta property="article:modified_time" content="2025-03-31T16:22:26-04:00"><meta property="article:tag" content="Software"><meta property="article:tag" content="Testing"><meta property="og:image" content="https://joshuapsteele.com/images/default-social.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://joshuapsteele.com/images/default-social.png"><meta name=twitter:title content="Software Testing: Possibilities, Problems, and Principles"><meta name=twitter:description content="Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.



Software Testing, Our Field’s Least-Sexy Superpower
Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://joshuapsteele.com/blog/"},{"@type":"ListItem","position":2,"name":"Software Testing: Possibilities, Problems, and Principles","item":"https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Software Testing: Possibilities, Problems, and Principles","name":"Software Testing: Possibilities, Problems, and Principles","description":"Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.\nSoftware Testing, Our Field’s Least-Sexy Superpower Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!\n","keywords":["software","testing"],"articleBody":"Note: Throughout what follows, I am heavily indebted to two books in particular: Unit Testing: Principles, Practices, and Patterns by Vladimir Khorikov (Manning Publications, 2020) and Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.\nSoftware Testing, Our Field’s Least-Sexy Superpower Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!\nSo I now think of software testing as software development’s least-sexy superpower.\nSure, tests aren’t very fun or glamorous to write and maintain. But can you imagine if other industries had similar testing powers?\nWhat if your house could test itself and let you know when it needed repairs? What if your body could test itself? What if, every day, you could live your life in the comfort of knowing that you and your belongings were being checked for errors thousands of times? Wouldn’t that be nice? Imagine the security and freedom that such a life-wide testing suite could provide!\nPossibilities of Software Testing I don’t know how far away we are from automatic home and health testing, but I do know that automated software testing has the potential to make our lives much better as we develop and sell software.\nSure, software development can get incredibly complicated and frustrating. But what if you had a robust testing suite that:\nCaught bugs Never “cried wolf” (“to cry wolf” = “to give a false alarm”) Was easy to run, understand, and change Good tests can help us confidently and quickly develop world-class software that improves our customers’ lives.\nIt’s not just about catching bugs and passing tests. As Vladimir Khorikov notes in Unit Testing: Principles, Practices, and Patterns, the goal of software testing “is to enable to sustainable growth of the software project.” The larger and longer a project is around, the more beneficial a good testing suite becomes.\nAfter all, a robust testing suite functions as its own form of documentation for your project. A developer should be able to read through the tests and quickly get up to speed with how the production code functions. They can then confidently make changes to the codebase, knowing that (1) they have a decent idea of how things work and (2) that the testing suite will alert them to breaking changes.\nAnd, as we’ll discuss below, well-designed code is easy to test! That is, there’s an important connection between software testing and software design. When we run into difficulties writing tests, we should consider improving the design of our production code.\nNow, speaking of testing difficulties…\nProblems with Software Testing All too often, the reality of software testing falls far short of its potential.\nThanks to the “test early, test often” perspective of “shift left” testing, most of us software engineers have to write tests. Most of our production code has an ever-increasing quantity of test code associated with it. (More on the different kinds of tests below.)\nBut the quality of our testing suites is often lacking.\nWe still have to put out fires more often than we’d like Our brittle tests “cry wolf” whenever we change anything Our tests are difficult to configure, understand, and refactor In other words, we’re not living up to our testing potential! Or, at least, I’m not! Instead, here’s what often happens:\nI make a change to the codebase Tests break I fix the tests My code quality/coverage analysis tool lets me know that I need more code coverage I either ignore my code coverage tool or add some low-quality tests to get the coverage that I need and move my PR forward This is bad! Don’t be like me! Don’t sacrifice test quality for test quantity.\nHow Can Josh We Test Better? What should we keep in mind when we prepare to write code, when tests break, when our code coverage tool gets mad, etc.?\nPrinciples of Software Testing Lots could and has been said about software testing. But I’d like to do an “80/20 analysis” of software testing and focus on the 20% of principles and mental models that yield 80% of the results.\nWhat is Software Testing? Simply put, software testing is the process of making sure that your software does what you want it to do.\nAs we’ll see below, the “process” can be quite complicated and multifaceted. But, before we get there, note that the prerequisite of software testing is knowing (at least partially) what you want your software to do!\nThis is a crucial point to remember, which brings us to our next principle.\nThe Absence of Errors Fallacy: Passing Tests Don’t Guarantee Good Software The absence of “errors” doesn’t mean that our software is useful, that it does the right things for our users!\nMauricio Aniche shares the following two quotes/sayings:\n“Coverage of code is easy to measure; coverage of requirements is another matter.” “Verification is about having the system right; validation is about having the right system.” Throughout the iterative process of software testing, we need to ask ourselves “Do we know what we want our software to do? Should we change the requirements to better meet our users’ needs?” Only then can we make sure that we are testing for the right behavior.\nQualities of a Good Test Khorikov (2020: 67) notes that a good testing suite “provides maximum value with minimum maintenance costs.” But, to achieve this, you need to be able to (1) “recognize a valuable test (and, by extension, a test of low value)” and (2) “write a valuable test.”\nTo get better at software testing, then, it’s helpful to know what we’re aiming for! Khorikov (2020: 68) lists four qualities of a good test:\nProtection against regressions\nResistance to refactoring\nFast feedback\nMaintainability\nHere’s how I would re-phrase that. A good automated software test:\nCatches bugs (no “false negatives”) Doesn’t “cry wolf” (no “false positives”) Runs quickly Is easy to read and run OK, so we should just max out each of these four qualities whenever writing tests, right?\nUnfortunately, it’s not so simple.\nThis is because, apart from Maintainability, the other three qualities are in tension with one another. You can only maximize two of the remaining three qualities.\n(Image source: Khorikov 2020)\nAnd, even then, you can’t completely forget about the last quality you’ve chosen not to prioritize! After all, no one wants a test that (1) doesn’t catch any bugs, (2) is so tightly coupled to the production code that it’s meaningless, or (3) takes forever to run.\nAvoid Brittle Tests: Maximize Resistance to Refactoring Should we prioritize any particular quality of a good test while we’re building our test suite?\nWhile we need to keep all four qualities in mind throughout the testing process, I agree with Khorikov when he argues for prioritizing resistance to refactoring. We need to take special care to avoid producing “brittle” tests that yield false positives (“cry wolf”) whenever we refactor our production code.\nPut simply, we need to test the what, not the how. (More on this in “Observable Behavior vs Implementation Details” below.) Our tests should be as loosely coupled to the implementation details of our production code as possible. Instead, they should focus on testing the observable behavior of our software.\nA related concept at this juncture is “black-box testing vs. white-box testing“:\nBlack-box testing: testing a system’s observable behavior, its specifications and requirements, as if you had no knowledge of its implementation details or inner workings White-box testing: testing a system’s implementation details and inner workings Black-box testing yields better resistance to refactoring. White-box testing might often uncover more bugs than black-box testing, but it often produces brittle tests that are too tightly coupled to implementation details.\nNevertheless, as Khorikov reminds us,\n“even though black-box testing is preferable when writing tests, you can still use the white-box method when analyzing the tests. Use code coverage tools to see which code branches are not exercised, but then turn around and test them as if you know nothing about the code’s internal structure. Such a combination of the white-box and black-box methods works best” (Khorikov 2020).\nWhy is resistance to refactoring worth prioritizing? Because, as Khorikov notes, unlike protection against regressions and fast feedback, which tend to exist on a spectrum, resistance to refactoring is more of an “all or nothing” aspect of a test.\n“The reason resistance to refactoring is non-negotiable is that whether a test possesses this attribute is mostly a binary choice: the test either has resistance to refactoring or it doesn’t. There are almost no intermediate stages in between. Thus you can’t concede just a little resistance to refactoring: you’ll have to lose it all. On the other hand, the metrics of protection against regressions and fast feedback are more malleable” (Khorikov 2020).\nA test is either brittle or it isn’t. And, while the cost of brittle tests is relatively low at the beginning of a project (as long as those tests are catching bugs and running relatively quickly), over time, as a project grows in size and complexity, the costs of brittle tests and their false positives drastically increases.\nThe main tradeoff we’re left with, then, is between “protection against regressions” and “fast feedback.” And this tradeoff plays itself out in the differences between the main kinds of software tests.\nKinds of Tests Fortunately, even though it’s impossible to write a perfect test that maximizes all the qualities of a good test at once, we can and should use different kinds of tests in our software testing suite.\nKeep in mind what’s known as “the pesticide paradox”–if you only use one type of test, or you fail to revise and evolve your testing suite, you’ll only catch certain kinds of bugs. To catch new defects in the system, you need to use different kinds of tests and constantly revise your testing suite.\nUnfortunately, there’s plenty of debate around the definition of test types, as well as when and how often to use each kind of test. Nevertheless, the following categories are commonly used:\nUnit tests Integration tests End-to-end tests (AKA System tests) This framework differentiates tests based on how much code they execute, how quickly they run, how complex they are, and how closely they mimic the behavior of an end user.\nUnit Tests Khorikov notes the disagreement on the precise definition of a unit test, but he helpfully isolates the following three attributes of a unit test that many definitions share:\n“A unit test is an automated test that\nVerifies a small piece of code (also known as a unit),\nDoes it quickly,\nAnd does it in an isolated manner.”\nNow, no one really disagrees that unit tests should run fast (#2). However, just what counts as a “unit” is a matter of some debate. Some people think that a “unit” is a single class or even a single method.\nHowever, as we’ll see below, there are advantages to broadening the definition of “unit” a little bit to mean “unit of work” or “unit of behavior.” Doing so helps us to write tests that are loosely coupled to the production code, tightly coupled to business/domain requirements, and therefore resistant to refactoring.\nI agree with Khorikov when he advises that\n“Tests shouldn’t verify units of code. Rather, they should verify units of behavior: something that is meaningful for the problem domain and, ideally, something that a business person can recognize as useful. The number of classes it takes to implement such a unit of behavior is irrelevant. The unit could span across multiple classes or only one class, or even take up just a tiny method.”\nBefore moving on, we should also note that people disagree on what it means for a unit test to be “isolated.”\nWhat’s known as the “London School” holds that:\nA unit is a single class Each unit should be tested in isolation from all other units Test doubles (mocks, stubs, etc.) should be used for everything except immutable dependencies (AKA “values” or “value objects”) Meanwhile, the “Classical School” (AKA “Detroit School”) maintains that:\nA unit is a unit of behavior, no matter how big/small Each unit test should run in isolation from all other unit tests Test doubles should only be used for shared dependencies (like a database or file system) It might already be obvious from my comment above about broadening the definition of “unit” to mean “unit of behavior/work,” but I prefer the Classical School’s perspective on testing. It’s easier to produce tests that are resistant to refactoring by following the Classical School’s paradigm.\nDespite all the disagreements about unit tests, it’s safe to say that everyone agrees that unit tests prioritize fast feedback. They’re quick to write, run, and let you know if you broke something.\nIntegration Tests Unlike unit tests, integration tests test more than one unit (although not the entire system). This means that they tend to take longer to write (and longer to run) than unit tests.\n(Note that, because “unit” is used in this definition as well, the arguments about unit tests bleed over into what counts as an integration test! What the “Classical School” calls unit tests, for example, would often be considered integration tests by the “London School.”)\nWhat integration tests give up in terms of fast feedback, they gain in terms of protection against regressions. That is, they can catch more bugs.\nThis is because integration tests exercise more of the codebase than unit tests. They also focus on the interactions between system components, which means that they’re looking for regressions/bugs in areas that are outside of the scope of unit tests.\nEnd-to-end or System Tests Unlike integration tests, end-to-end or system tests test the entire system. They take even longer to write and run than integration tests, but they emulate an end-user’s interactions with your system more than any other kind of test.\nSystem tests maximize protection against regressions by exercising the entire code base.\nUsing all three different kinds of tests, then, is key to having a test suite that catches bugs and gives fast feedback.\n(Image source: Khorikov 2020)\nThe Test Pyramid Due to the strengths and weaknesses of the three different kinds of tests, the “test pyramid” model suggests that developers should write many unit tests, fewer integration tests, and even fewer end-to-end tests. The width of the pyramid represents the number of tests at each level.\nHere is Mauricio Aniche’s version of the Test Pyramid, which adds exploratory manual testing (vs. automated testing) as a top layer:\n(Image source: Aniche 2022)\nThe main reason to be sparing in our creation and use of integration and system tests is time. Remember, one of the four qualities of a good test is “fast feedback,” and this is definitely a weakness of integration and system tests.\nNevertheless, because they exercise a lot of the codebase (and thereby increase our code coverage), integration and system tests are particularly good at catching bugs. So, if we want our testing suite to be good at “protection against regressions,” we need to include well-thought-out integration and system tests.\nCode Coverage: Good Servant, Bad Master Code coverage is a measurement of how much of your production code gets executed by your test code.\nOn its own, “code coverage” usually refers to “line coverage,” meaning the number of lines of code executed by your tests divided by the total lines of code. (If you’ve got 100 lines of code and your tests execute 90 of them, you’ve got 90% code coverage.)\nHowever, as Aniche (2022) notes, because the complexity of our production code involves more than just the number of lines of code, there are other forms/aspects of code coverage worth considering.\nBranch coverage takes into account all the true and false branches of the program’s logic (coverage of if(a \u0026\u0026 b) must test for both a \u0026\u0026 b == true and a \u0026\u0026 b == false) Condition and branch coverage builds upon branch coverage to consider each condition that’s a part of a true or false branch (coverage of if(a || b) must test for a == true/b == false, a == false/b == true, and a == false/b == false) Path coverage is the strictest criteria, considering each and every possible path through the program’s logic (coverage of a program with 10 independent true/false conditions would require 210 = 1024 test cases) In a perfect world, we might always want to shoot for 100% path coverage. But, realistically, achieving full path coverage for complicated production code is far too time-consuming to be valuable.\nKhorikov lists two main problems with code coverage metrics:\nYou can’t guarantee that the test verifies all the possible outcomes of the system under test.\nNo coverage metric can take into account code paths in external libraries.\nRegarding the former problem, the combination of implicit and explicit outcomes of the system under test makes it extremely difficult, if not impossible, to test for them all. And, regarding the latter, code coverage metrics do not take the use of external libraries into consideration.\nDoes this, then, mean we should not care about code coverage?\nNo! But, we should keep in mind that, as Khorikov puts it, “coverage metrics are a good negative indicator, but a bad positive one.”\nThis is related to the “absence-of-errors fallacy” mentioned above. That is, if you have very low code coverage, it’s a sure sign that your testing suite has problems. But the mere fact of a high code coverage percentage does not mean that you have a robust testing suite.\nMC/DC Coverage Before we move on from code coverage completely, however, I want to mention what’s known as “modified condition / decision coverage” or “MC/DC” as a way to maximize the value of code coverage while minimizing the number of test cases required.\nAs Aniche (2022) summarizes it, MC/DC\n“looks at combinations of conditions, as path coverage does. However, instead of testing all possible combinations, we identify the important combinations that need to be tested. MC/DC exercises each of these conditions so that it can, independently of the other conditions, affect the outcome of the entire decision. Every possible condition of each parameter must influence the outcome at least once.”\nTo achieve MC/DC, you list all possible test cases (those required if you were going for path coverage), before searching for “independence pairs” of test cases where (1) a single condition change (2) independently changes the outcome of the code in question. After finding these independence pairs for all of the conditions, you can reduce the list of test cases down to at least one independence pair for each condition under test.\nIf we’re just considering binary true/false conditions, then MC/DC requires N + 1 test cases vs path coverage’s 2N test cases (Aniche 2022, citing Chilenski 2001).\nWhile MC/DC isn’t a silver bullet to solve all code coverage issues, it’s a great example of applying the “test the what, not the how” testing principle to the topic of code coverage. When deciding which test cases to (not) write, we want to make sure that we’re covering the aspects of our software’s logic that influence it’s observable behavior.\nWell-Designed Code is Easy to Test A deep-dive into software design and architecture far exceeds the scope of this overview of software testing principles. Nevertheless, there’s an important connection between software testing and software design.\nCode that is well-designed is easy to test. And code that is difficult to test is often poorly designed.\nWhen testing is integrated into the software development process, then any friction encountered when writing tests should raise questions about the way the production code is structured. Granted, certain difficulties cannot be avoided (sometimes requirements demand behavior that is inherently difficult to test). But there are often ways to improve the design of our production code while also making it easier to test.\nKeep Domain and Infrastructure Code Separate This is the main design principle that Aniche emphasizes in his chapter on “Designing for testability” in Effective Software Testing (2022):\nThe domain is where the core of the system lies: that is, where all the business rules, logic, entities, services, and similar elements reside. … Infrastructure relates to all code that handles an external dependency: for example, pieces of code that handle database queries (in this case, the database is an external dependency) or web service calls or file reads and writes. In our previous examples, all of our data access objects (DAOs) are part of the infrastructure code.\nIn practice, when domain code and infrastructure code are mixed, the system becomes harder to test. You should separate them as much as possible so the infrastructure does not get in the way of testing.”\nKeeping domain code (AKA “business logic”) separate from infrastructure code (AKA “application services layer”) is a key emphasis of the “Hexagonal Architecture” or “Ports and Adapters” pattern.\nThe business logic at the “center” of your application should only interact with external dependencies by interacting with ports (application services), that interact with adapters, that are themselves coupled to the external dependencies.\n(Image source: Aniche 2022)\nThis “separation of concerns” approach to software design increases the testability of a system because it allows us to focus our testing efforts, especially at the unit-test level, on the most important part of the system—the domain code—without directly relying on any external dependencies (which could slow our tests down, make them unpredictable, etc.).\nKeeping domain code separate from infrastructure code also helps us to avoid writing brittle tests by emphasizing a key principle behind “resistance to refactoring”—observable behavior vs implementation details.\nObservable Behavior vs Implementation Details At each level of a system, there is an important distinction between what the system is accomplishing (the observable behavior) and how it accomplishes it (implementation details).\nAt the highest level, inter-system communications between applications are observable behaviors, while intra-system communication between classes inside an application are implementation details.\n(Image source: Khorikov 2020)\nRemember that, as we test each level of the system, in order to avoid writing brittle tests that throw false positives, we need to test the observable behavior, and not the implementation details.\nAt first glance, it might seem like the distinction is between observable behavior and implementation details is the same as between an applications public API (application programming interface) and its private API. In languages like C# and Java, this public/private distinction is usually achieved using access modifiers (public, private, protected, etc.).\nHowever, although a well-designed API has a public API that coincides with its observable behavior and a private API that coincides with its implementation details, it’s very easy and common for an application to “leak” its implementation details into its public API by making those implementation details inappropriately observable.\nKhorikov highlights the differences here as follows:\n“For a piece of code to be part of the system’s observable behavior, it has to do one of the following things:\nExpose an operation that helps the client achieve one of its goals. An operation is a method that performs a calculation or incurs a side effect or both.\nExpose a state that helps the client achieve on of its goals. State is the current condition of the system.\nAny code that does neither of these two things is an implementation detail.”\nWhenever an application “leaks” its implementation details into its public API, it makes it easy for developers to write brittle tests. As Khorikov observes, “by making all implementation details private, you leave your tests no choice other than to verify the code’s observable behavior, which automatically improves their resistance to refactoring.”\nFour Types of Code: Complexity/Significance vs Number of Dependencies In addition to the distinction between observable behavior and implementation details, there’s an important framework to keep in mind when determining how to test each part of our software system.\n(Image source: Khorikov 2020)\nKhorikov lists the following four types of production code:\nDomain model and algorithms (top left)—Complex code is often part of the domain model but not in 100% of all cases. You might have a complex algorithm that’s not directly related to the problem domain.\nTrivial code (bottom left)—Examples of such code in C# are parameter-less constructors and one-line properties: they have few (if any) collaborators and exhibit little complexity or domain significance.\nControllers (bottom right)—This code doesn’t do complex or business-critical work by itself but coordinates the work of other components like domain classes and external applications.\nOvercomplicated code (top right)—Such code scores highly on both metrics: it has a lot of collaborators, and it’s also complex or important. An example here are fat controllers (controllers that don’t delegate complex work anywhere and do everything themselves).\nAlthough trivial code is difficult, if not impossible, to avoid, well-designed software systems avoid “overcomplicated code” by making sure that code is either complex/significant OR it works with a number of dependencies, but not both at the same time.\nPut differently, the more complicated the code, or the more significant for the domain layer, the fewer collaborators it should have.\nWhy? Because, at least from a testing perspective, collaborators are expensive and time-consuming to test. Restricting interaction with collaborators to “controllers” in the application services / infrastructure layer of our application allows us to be strategic in our use of test doubles and integration tests for the controllers, while spending more of our valuable time writing unit tests for our domain code and complex algorithms.\n![UnitTesting08fig01_alt.jpeg](https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/D2685F77-D498-4959-9B7D-6FF2DEEAC26A_2/IP8Scjkvxo8Egqj2Fz8ly0vviNmuKTxCKtz97Fyfz5sz/UnitTesting08fig01_alt.jpeg)UnitTesting08fig01\\_alt.jpeg (Image source: [Khorikov 2020](https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/)) If the classes in our domain code depend only on each other, they should be relatively easy and quick to unit test. Then, after checking as many edge cases as possible in our unit tests, we can judiciously test the happy paths and all other edge cases in our integration tests of the controllers in the application service layer.\nNevertheless, even if we do all of this properly, we still need to reckon with collaborators and dependencies at some point, ideally without making our testing suite prohibitively expensive and time-consuming to run! This brings us to the important topic of test doubles.\nTest Doubles: Mocks vs Stubs Test doubles (think “stunt doubles”) mimic the behavior of dependencies. There are various kinds of test doubles. Aniche (2022) lists five, for example:\nDummies: passed to the class under test but never used Fakes: use simplified implementations of the classes they mimic Stubs: provide hard-coded answers to queries (no simplified implementation like fakes) Mocks: provide hard-coded answers to queries, recording the interactions that can then be asserted afterward Spies: wrap around a real dependency object (not like a mock), recording the interactions (like a mock) However, Khorikov (2020) helpfully simplifies this list down to just two kinds of test doubles:\nMocks (including both mocks and spies) Stubs (including dummies, fakes, and stubs) What’s the difference between the two? Here’s Khorikov again:\nMocks help to emulate and examine outcoming interactions. These interactions are calls the SUT [System Under Test] makes to its dependencies to change their state.\nStubs help to emulate incoming interactions. These interactions are calls the SUT makes to its dependencies to get input data\nNotice two important things. First, mocks both emulate and examine, while stubs only emulate. Second, mocks mimic interactions that result in side effects or changed state, while stubs mimc interactions that retrieve information. This touches on another important principle: command query separation.\nCommand Query Separation According to command query separation (CQS), “every method should be either a command or a query, but not both” (Khorikov 2020).\nCommands: produce side effects, but do not return a value Queries: return a value, but do not produce side effects Another way of summarizing this principle is that “asking a question should not change the answer” (Khorikov 2020).\nNote that, in terms of CQS, mocks mimic commands while stubs mimic queries.\n(Image source: Khorikov 2020)\nWhen to Use Mocks and Stubs A corollary of what we’ve just discussed is that we should never assert (verify) interactions with stubs in our tests. Doing so is unnecessary if our tests are correctly focusing on observable behavior, because stubs should only ever emulate steps on the way to our SUT (system under test) producing observable output.\nA corollary of what we previously discussed about complexity/significance vs number of collaborators means that we should not have to use test doubles in our unit tests of domain code (and complex algorithms), but should rather save mocks and stubs for our integration tests of controllers and application services code.\nPut differently: save test doubles for the outside “edges” of your system, where you need to verify interactions with dependencies that you don’t have control over.\nWhen unit testing domain code classes at the “center” of your system, the only direct dependencies should be upon other domain code classes. And, since we’ve already discussed the benefit of expanding our definition of “unit” beyond “class” to include “unit of behavior/work,” we should use real versions of these “in-process” dependencies in our unit tests, instead of replacing them with mocks or stubs.\nAnd, even when writing integration tests for application service code, when interactions with “out-of-process” dependencies are inescapable, we should only replace unmanaged out-of-process dependencies with test doubles. Whenever possible, we should use real instances of managed out-of-process dependencies (such as a database) in our integration tests, rather than replacing these with mocks or stubs.\nFinally, when replacing unmanaged dependencies with test doubles, we should do so by creating (and then mocking or stubbing) an adapter layer that stands between our application and the third-party dependency. In other words, even when mocking a dependency you don’t control, you should “only mock types that you own” (Khorikov 2020). This doesn’t mean that you should mock managed dependencies like your database (see above)! But it does add in a helpful buffer between your application and its unmanaged dependencies.\nConclusion Much more could be (and has been) said about software testing! If I had more time, I would discuss the following. But I recommend that curious readers do their own research on:\nParameterized testing, which can help save time and space when you’ve got a bunch of test cases you need to cover for a single method Property-based testing, which leverages software to create and handle test cases given pre-defined “properties” or parameters that should be followed when generating possible inputs for your tests Mutation testing, which makes dynamic changes (“mutants”!) to your production code, and then sees whether or not those changes cause a test to fail (if, say, changing an if (A) to if (!A) causes a test to fail, then you’ve “killed” the mutant; if changing the logic of your program doesn’t cause any tests to fail, then the mutant has “survived”) …Not to mention doing your own research on testing libraries and frameworks in your favorite language(s)! (In Java world, that includes JUnit, Mockito, jqwik, AssertJ, Pitest, etc.)\nNevertheless, I hope that this overview of software testing possibilities, problems, and principles helps you to write better tests and develop better software! If you have anything to add or correct, please do leave a comment. Or reach out to me (Twitter @joshuapsteele, GitHub jsteelepfpt, LinkedIn joshuapsteele).\nRecommended Resources on Software Testing Test Case Checklist in Code Complete, 2nd edition by Steve McConnell (Microsoft 2004:532) Effective Software Testing: A Developer’s Guide by Mauricio Aniche (Manning, 2022) Full Stack Testing: A Practical Guide for Delivering High Quality Software by Gayathri Mohan (O’Reilly, 2022) Unit Testing Principles, Practices, and Patterns by Vladimir Khorikov (Manning, 2020) “Topic 41: Test to Code” and “Topic 42: Property-Based Testing” in The Pragmatic Programmer: Your Journey to Mastery by David Thomas and Andrew Hunt (2nd Edition; Addison-Wesley Professional, 2019) “Testing Strategies in a Microservice Architecture” by Toby Clemson (Slide Deck) “What Is Software Testing? And Why Is It So Hard?” by James A. Whittaker (IEEE Software, January 2000:70–79) ","wordCount":"5322","inLanguage":"en","image":"https://joshuapsteele.com/images/default-social.png","datePublished":"2022-12-21T21:08:05Z","dateModified":"2025-03-31T16:22:26-04:00","author":{"@type":"Person","name":"joshuapsteele"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://joshuapsteele.com/software-testing-possibilities-problems-and-principles/"},"publisher":{"@type":"Organization","name":"Joshua P. Steele","logo":{"@type":"ImageObject","url":"https://joshuapsteele.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://joshuapsteele.com/ accesskey=h title="Joshua P. Steele (Alt + H)">Joshua P. Steele</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://joshuapsteele.com/about/ title=About><span>About</span></a></li><li><a href=https://joshuapsteele.com/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://joshuapsteele.com/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://joshuapsteele.com/resources/ title=Resources><span>Resources</span></a></li><li><a href=https://social.joshuapsteele.com title=Social><span>Social</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=https://joshuapsteele.com/search title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://joshuapsteele.com/>Home</a>&nbsp;»&nbsp;<a href=https://joshuapsteele.com/blog/>Blogs</a></div><h1 class="post-title entry-hint-parent">Software Testing: Possibilities, Problems, and Principles</h1><div class=post-meta><span title='2022-12-21 21:08:05 +0000 UTC'>December 21, 2022</span>&nbsp;·&nbsp;25 min&nbsp;·&nbsp;joshuapsteele&nbsp;|&nbsp;<a href=https://github.com/joshuapsteele/joshuapsteele.github.io/tree/main/content/blog/software-testing-possibilities-problems-and-principles.md rel="noopener noreferrer" target=_blank>View on GitHub</a>
<span class=post-meta-item><span class=post-meta-separator>|</span>
<button class=tinylytics_kudos data-path=/software-testing-possibilities-problems-and-principles/></button></span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#software-testing-our-fields-least-sexy-superpower aria-label="Software Testing, Our Field’s Least-Sexy Superpower">Software Testing, Our Field’s Least-Sexy Superpower</a></li><li><a href=#possibilities-of-software-testing aria-label="Possibilities of Software Testing">Possibilities of Software Testing</a></li><li><a href=#problems-with-software-testing aria-label="Problems with Software Testing">Problems with Software Testing</a></li><li><a href=#how-can-josh-we-test-better aria-label="How Can Josh We Test Better?">How Can Josh We Test Better?</a></li><li><a href=#principles-of-software-testing aria-label="Principles of Software Testing">Principles of Software Testing</a><ul><li><a href=#what-is-software-testing aria-label="What is Software Testing?">What is Software Testing?</a></li><li><a href=#the-absence-of-errors-fallacy-passing-tests-dont-guarantee-good-software aria-label="The Absence of Errors Fallacy: Passing Tests Don’t Guarantee Good Software">The Absence of Errors Fallacy: Passing Tests Don’t Guarantee Good Software</a></li><li><a href=#qualities-of-a-good-test aria-label="Qualities of a Good Test">Qualities of a Good Test</a></li><li><a href=#avoid-brittle-tests-maximize-resistance-to-refactoring aria-label="Avoid Brittle Tests: Maximize Resistance to Refactoring">Avoid Brittle Tests: Maximize Resistance to Refactoring</a></li><li><a href=#kinds-of-tests aria-label="Kinds of Tests">Kinds of Tests</a><ul><li><a href=#unit-tests aria-label="Unit Tests">Unit Tests</a></li><li><a href=#integration-tests aria-label="Integration Tests">Integration Tests</a></li><li><a href=#end-to-end-or-system-tests aria-label="End-to-end or System Tests">End-to-end or System Tests</a></li></ul></li><li><a href=#the-test-pyramid aria-label="The Test Pyramid">The Test Pyramid</a></li><li><a href=#code-coverage-good-servant-bad-master aria-label="Code Coverage: Good Servant, Bad Master">Code Coverage: Good Servant, Bad Master</a></li><li><a href=#mcdc-coverage aria-label="MC/DC Coverage">MC/DC Coverage</a></li><li><a href=#well-designed-code-is-easy-to-test aria-label="Well-Designed Code is Easy to Test">Well-Designed Code is Easy to Test</a></li><li><a href=#keep-domain-and-infrastructure-code-separate aria-label="Keep Domain and Infrastructure Code Separate">Keep Domain and Infrastructure Code Separate</a></li><li><a href=#observable-behavior-vs-implementation-details aria-label="Observable Behavior vs Implementation Details">Observable Behavior vs Implementation Details</a></li><li><a href=#four-types-of-code-complexitysignificance-vs-number-of-dependencies aria-label="Four Types of Code: Complexity/Significance vs Number of Dependencies">Four Types of Code: Complexity/Significance vs Number of Dependencies</a></li><li><a href=#test-doubles-mocks-vs-stubs aria-label="Test Doubles: Mocks vs Stubs">Test Doubles: Mocks vs Stubs</a></li><li><a href=#command-query-separation aria-label="Command Query Separation">Command Query Separation</a></li><li><a href=#when-to-use-mocks-and-stubs aria-label="When to Use Mocks and Stubs">When to Use Mocks and Stubs</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#recommended-resources-on-software-testing aria-label="Recommended Resources on Software Testing">Recommended Resources on Software Testing</a></li></ul></div></details></div><div class=post-content><p>Note: Throughout what follows, I am heavily indebted to two books in particular: <a href=https://www.manning.com/books/unit-testing>Unit Testing: Principles, Practices, and Patterns</a> by <a href="https://twitter.com/vkhorikov?lang=en">Vladimir Khorikov</a> (Manning Publications, 2020) and <a href=https://www.manning.com/books/effective-software-testing>Effective Software Testing: A Developer’s Guide</a> by <a href=https://twitter.com/mauricioaniche>Mauricio Aniche</a> (Manning Publications, 2022). In fact, this overview of software testing should be viewed as a distillation of Khorikov and Aniche.</p><p><img alt=Khorikov-UT-HI.png loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/21ECE62D-593E-4825-A549-6312F555D284_2/ZCHd2JrecxcxPA1c35H2wTV0FrAzdktnxui31U1rO00z/Khorikov-UT-HI.png></p><p><img alt=Aniche-HI.png loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/ED1FC92B-C9A0-4CDC-B13D-5AA3940FF3E7_2/FE2KZaydLyYRh1ydJKyDIvx4y3gaQLh82funASwXFqoz/Aniche-HI.png></p><hr><h2 id=software-testing-our-fields-least-sexy-superpower>Software Testing, Our Field’s Least-Sexy Superpower<a hidden class=anchor aria-hidden=true href=#software-testing-our-fields-least-sexy-superpower>#</a></h2><p>Coming into software development from a background in the humanities, automated software testing struck me as a kind of superpower. Until, that is, I had to write my first software test!</p><p>So I now think of software testing as software development’s least-sexy superpower.</p><p>Sure, tests aren’t very fun or glamorous to write and maintain. But can you imagine if other industries had similar testing powers?</p><p>What if your house could test itself and let you know when it needed repairs? What if your body could test itself? What if, every day, you could live your life in the comfort of knowing that you and your belongings were being checked for errors thousands of times? Wouldn’t that be nice? Imagine the security and freedom that such a life-wide testing suite could provide!</p><p><img loading=lazy src="https://images.unsplash.com/photo-1576267423445-b2e0074d68a4?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw3fHxoYXBweSUyMGNvbXB1dGVyfGVufDB8fHx8MTY2NTQ5MjI5MQ&ixlib=rb-1.2.1&q=80&w=1080"></p><h2 id=possibilities-of-software-testing>Possibilities of Software Testing<a hidden class=anchor aria-hidden=true href=#possibilities-of-software-testing>#</a></h2><p>I don’t know how far away we are from automatic home and health testing, but I do know that automated software testing has the potential to make our lives much better as we develop and sell software.</p><p>Sure, software development can get incredibly complicated and frustrating. But what if you had a robust testing suite that:</p><ol><li>Caught bugs</li><li>Never “<a href=https://en.wikipedia.org/wiki/The_Boy_Who_Cried_Wolf>cried wolf</a>” (“to cry wolf” = “to give a false alarm”)</li><li>Was easy to run, understand, and change</li></ol><p>Good tests can help us confidently and quickly develop world-class software that improves our customers’ lives.</p><p>It’s not just about catching bugs and passing tests. As Vladimir Khorikov notes in <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/><em>Unit Testing: Principles, Practices, and Patterns</em></a>, <strong>the goal of software testing “is to enable to sustainable growth of the software project.”</strong> The larger and longer a project is around, the more beneficial a good testing suite becomes.</p><p>After all, a robust testing suite functions as its own form of <strong>documentation</strong> for your project. A developer should be able to read through the tests and quickly get up to speed with how the production code functions. They can then confidently make changes to the codebase, knowing that (1) they have a decent idea of how things work and (2) that the testing suite will alert them to breaking changes.</p><p>And, as we’ll discuss below, <a href=https://docs.craft.do/editor/d/032236cd-2bcc-fa12-9dfe-e5564a597e07/836657DD-FF3A-4CE5-8565-F6945FE45D6A/b/C94D92D2-AC78-4BCC-AB6B-5388B77EAF8B#8434D46D-25CD-49D8-83AC-87FE1E45A738>well-designed code is easy to test</a>! That is, there’s an important connection between software testing and software <strong>design</strong>. When we run into difficulties writing tests, we should consider improving the design of our production code.</p><p>Now, speaking of testing difficulties…</p><p><img loading=lazy src="https://images.unsplash.com/photo-1516534775068-ba3e7458af70?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw1fHxmcnVzdHJhdGVkfGVufDB8fHx8MTY2NTQ5MjMxNw&ixlib=rb-1.2.1&q=80&w=1080"></p><h2 id=problems-with-software-testing>Problems with Software Testing<a hidden class=anchor aria-hidden=true href=#problems-with-software-testing>#</a></h2><p>All too often, the reality of software testing falls far short of its potential.</p><p>Thanks to the “test early, test often” perspective of <a href=https://www.testim.io/blog/shift-left-testing-guide/>“shift left” testing</a>, most of us software engineers have to write tests. Most of our production code has an ever-increasing <strong>quantity</strong> of test code associated with it. (More on the different <a href=https://docs.craft.do/editor/d/032236cd-2bcc-fa12-9dfe-e5564a597e07/836657DD-FF3A-4CE5-8565-F6945FE45D6A/b/C94D92D2-AC78-4BCC-AB6B-5388B77EAF8B#AA5E8A29-25DD-4777-80AD-37DF0A172857>kinds of tests</a> below.)</p><p>But the <strong>quality</strong> of our testing suites is often lacking.</p><ul><li>We still have to put out fires more often than we’d like</li><li>Our brittle tests “cry wolf” whenever we change anything</li><li>Our tests are difficult to configure, understand, and refactor</li></ul><p>In other words, we’re not living up to our testing potential! Or, at least, <strong>I’m</strong> not! Instead, here’s what often happens:</p><ul><li>I make a change to the codebase</li><li>Tests break</li><li>I fix the tests</li><li>My <a href=https://www.sonarqube.org/>code quality/coverage analysis tool</a> lets me know that I need more code coverage</li><li>I either</li><li>ignore my code coverage tool or</li><li>add some low-quality tests to get the coverage that I need and move my PR forward</li></ul><p>This is bad! Don’t be like me! Don’t sacrifice test quality for test quantity.</p><h2 id=how-can-josh-we-test-better>How Can <del>Josh</del> We Test Better?<a hidden class=anchor aria-hidden=true href=#how-can-josh-we-test-better>#</a></h2><p>What should we keep in mind when we prepare to write code, when tests break, when our code coverage tool gets mad, etc.?</p><hr><p><img loading=lazy src="https://images.unsplash.com/photo-1598520106830-8c45c2035460?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHwxfHx3aGl0ZWJvYXJkfGVufDB8fHx8MTY2NTQ5MjE1Ng&ixlib=rb-1.2.1&q=80&w=1080"></p><h2 id=principles-of-software-testing>Principles of Software Testing<a hidden class=anchor aria-hidden=true href=#principles-of-software-testing>#</a></h2><p>Lots could and has been said about software testing. But I’d like to do an “80/20 analysis” of software testing and focus on the 20% of principles and mental models that yield 80% of the results.</p><h3 id=what-is-software-testing>What is Software Testing?<a hidden class=anchor aria-hidden=true href=#what-is-software-testing>#</a></h3><p>Simply put, <strong>software testing is the process of making sure that your software does what you want it to do</strong>.</p><p>As we’ll see below, the “process” can be quite complicated and multifaceted. But, before we get there, note that <strong>the prerequisite of software testing is knowing (at least partially) what you want your software to do!</strong></p><p>This is a crucial point to remember, which brings us to our next principle.</p><h3 id=the-absence-of-errors-fallacy-passing-tests-dont-guarantee-good-software>The <a href=https://www.oodlestechnologies.com/blogs/understanding-absence-of-error-fallacy-in-software-testing/>Absence of Errors Fallacy</a>: Passing Tests Don’t Guarantee Good Software<a hidden class=anchor aria-hidden=true href=#the-absence-of-errors-fallacy-passing-tests-dont-guarantee-good-software>#</a></h3><p>The absence of “errors” doesn’t mean that our software is useful, that it does the right things for our users!</p><p>Mauricio Aniche shares the following two quotes/sayings:</p><ul><li>“Coverage of code is easy to measure; coverage of requirements is another matter.”</li><li>“Verification is about having the system right; validation is about having the right system.”</li></ul><p>Throughout the iterative process of software testing, we need to ask ourselves <strong>“Do we know what we want our software to do? Should we change the requirements to better meet our users’ needs?”</strong> Only then can we make sure that we are testing for the right behavior.</p><h3 id=qualities-of-a-good-test>Qualities of a Good Test<a hidden class=anchor aria-hidden=true href=#qualities-of-a-good-test>#</a></h3><p>Khorikov (2020: 67) notes that a good testing suite “provides maximum value with minimum maintenance costs.” But, to achieve this, you need to be able to (1) “recognize a valuable test (and, by extension, a test of low value)” and (2) “write a valuable test.”</p><p>To get better at software testing, then, it’s helpful to know what we’re aiming for! Khorikov (2020: 68) lists four qualities of a good test:</p><ul><li><blockquote><p>Protection against regressions</p></blockquote></li><li><blockquote><p>Resistance to refactoring</p></blockquote></li><li><blockquote><p>Fast feedback</p></blockquote></li><li><blockquote><p>Maintainability</p></blockquote></li></ul><p>Here’s how I would re-phrase that. A good automated software test:</p><ol><li>Catches bugs (no “false negatives”)</li><li>Doesn’t “cry wolf” (no “false positives”)</li><li>Runs quickly</li><li>Is easy to read and run</li></ol><p>OK, so we should just max out each of these four qualities whenever writing tests, right?</p><p>Unfortunately, it’s not so simple.</p><p>This is because, apart from Maintainability, the other three qualities are in tension with one another. You can only maximize two of the remaining three qualities.</p><p><img alt=UnitTesting04fig08_alt.jpeg loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/97683B15-BF10-416A-B336-4182179A0E2A_2/bpWRZyrcBDzP71Nk97VopU9hJSQf30X0WDoxASNykDkz/UnitTesting04fig08_alt.jpeg>
(Image source: <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/>Khorikov 2020</a>)</p><p>And, even then, you can’t completely forget about the last quality you’ve chosen not to prioritize! After all, no one wants a test that (1) doesn’t catch any bugs, (2) is so tightly coupled to the production code that it’s meaningless, or (3) takes forever to run.</p><p><img loading=lazy src="https://images.unsplash.com/photo-1508935620299-047e0e35fbe3?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHwxfHxicm9rZW58ZW58MHx8fHwxNjY1NDkyNTcw&ixlib=rb-1.2.1&q=80&w=1080"></p><h3 id=avoid-brittle-tests-maximize-resistance-to-refactoring>Avoid Brittle Tests: Maximize Resistance to Refactoring<a hidden class=anchor aria-hidden=true href=#avoid-brittle-tests-maximize-resistance-to-refactoring>#</a></h3><p>Should we prioritize any particular quality of a good test while we’re building our test suite?</p><p>While we need to keep all four qualities in mind throughout the testing process, I agree with Khorikov when he argues for <strong>prioritizing resistance to refactoring</strong>. We need to take special care to avoid producing “brittle” tests that yield false positives (“cry wolf”) whenever we refactor our production code.</p><p>Put simply, we need to <strong>test the what, not the how</strong>. (More on this in “<a href="craftdocs://open?blockId=9811D0C8-FEBE-42CC-BA53-9A767F01549F&amp;spaceId=032236cd-2bcc-fa12-9dfe-e5564a597e07">Observable Behavior vs Implementation Details</a>” below.) Our tests should be as loosely coupled to the implementation details of our production code as possible. Instead, they should focus on testing the observable behavior of our software.</p><p>A related concept at this juncture is <strong>“black-box testing vs. white-box testing</strong>“:</p><ul><li>Black-box testing: testing a system’s observable behavior, its specifications and requirements, as if you had no knowledge of its implementation details or inner workings</li><li>White-box testing: testing a system’s implementation details and inner workings</li></ul><p>Black-box testing yields better resistance to refactoring. White-box testing might often uncover more bugs than black-box testing, but it often produces brittle tests that are too tightly coupled to implementation details.</p><p>Nevertheless, as Khorikov reminds us,</p><blockquote><p>“even though black-box testing is preferable when <em>writing tests</em>, you can still use the white-box method when <em>analyzing</em> the tests. <em>Use code coverage tools to see which code branches are not exercised, but then turn around and test them as if you know nothing about the code’s internal structure.</em> Such a combination of the white-box and black-box methods works best” (Khorikov 2020).</p></blockquote><p>Why is resistance to refactoring worth prioritizing? Because, as Khorikov notes, unlike protection against regressions and fast feedback, which tend to exist on a spectrum, resistance to refactoring is more of an “all or nothing” aspect of a test.</p><blockquote><p>“The reason resistance to refactoring is non-negotiable is that whether a test possesses this attribute is mostly a binary choice: the test either has resistance to refactoring or it doesn’t. There are almost no intermediate stages in between. Thus you can’t concede just a little resistance to refactoring: you’ll have to lose it all. On the other hand, the metrics of protection against regressions and fast feedback are more malleable” (Khorikov 2020).</p></blockquote><p>A test is either brittle or it isn’t. And, while the cost of brittle tests is relatively low at the beginning of a project (as long as those tests are catching bugs and running relatively quickly), over time, as a project grows in size and complexity, the costs of brittle tests and their false positives drastically increases.</p><p>The main tradeoff we’re left with, then, is between “protection against regressions” and “fast feedback.” And this tradeoff plays itself out in the differences between the main kinds of software tests.</p><h3 id=kinds-of-tests>Kinds of Tests<a hidden class=anchor aria-hidden=true href=#kinds-of-tests>#</a></h3><p>Fortunately, even though it’s impossible to write a perfect test that maximizes all the qualities of a good test at once, we can and should use different kinds of tests in our software testing suite.</p><p>Keep in mind what’s known as “the pesticide paradox”–if you only use one type of test, or you fail to revise and evolve your testing suite, you’ll only catch certain kinds of bugs. To catch new defects in the system, you need to use different kinds of tests and constantly revise your testing suite.</p><p>Unfortunately, there’s plenty of debate around the definition of test types, as well as when and how often to use each kind of test. Nevertheless, the following categories are commonly used:</p><ul><li>Unit tests</li><li>Integration tests</li><li>End-to-end tests (AKA System tests)</li></ul><p>This framework differentiates tests based on how much code they execute, how quickly they run, how complex they are, and how closely they mimic the behavior of an end user.</p><h4 id=unit-tests>Unit Tests<a hidden class=anchor aria-hidden=true href=#unit-tests>#</a></h4><p>Khorikov notes the disagreement on the precise definition of a unit test, but he helpfully isolates the following <strong>three attributes of a unit test</strong> that many definitions share:</p><blockquote><p>“A unit test is an automated test that</p></blockquote><ol><li><blockquote><p>Verifies a small piece of code (also known as a <em>unit</em>),</p></blockquote></li><li><blockquote><p>Does it quickly,</p></blockquote></li><li><blockquote><p>And does it in an isolated manner.”</p></blockquote></li></ol><p>Now, no one really disagrees that unit tests should run <strong>fast</strong> (#2). However, just what counts as a <strong>“unit”</strong> is a matter of some debate. Some people think that a “unit” is a single class or even a single method.</p><p>However, as we’ll see below, there are advantages to broadening the definition of “unit” a little bit to mean <strong>“unit of work” or “unit of behavior.”</strong> Doing so helps us to write tests that are loosely coupled to the production code, tightly coupled to business/domain requirements, and therefore resistant to refactoring.</p><p>I agree with Khorikov when he advises that</p><blockquote><p>“Tests shouldn’t verify <em>units of code</em>. Rather, they should verify <em>units of behavior</em>: something that is meaningful for the problem domain and, ideally, something that a business person can recognize as useful. The number of classes it takes to implement such a unit of behavior is irrelevant. The unit could span across multiple classes or only one class, or even take up just a tiny method.”</p></blockquote><p>Before moving on, we should also note that people disagree on what it means for a unit test to be <strong>“isolated.”</strong></p><p>What’s known as the <a href=https://medium.com/@adrianbooth/test-driven-development-wars-detroit-vs-london-classicist-vs-mockist-9956c78ae95f><strong>“London School”</strong></a> holds that:</p><ul><li>A <strong>unit</strong> is a <strong>single class</strong></li><li>Each unit should be tested in <strong>isolation from all other units</strong></li><li><strong>Test doubles</strong> (mocks, stubs, etc.) should be used for <strong>everything except immutable dependencies</strong> (AKA “values” or “value objects”)</li></ul><p>Meanwhile, the <a href=https://medium.com/@adrianbooth/test-driven-development-wars-detroit-vs-london-classicist-vs-mockist-9956c78ae95f><strong>“Classical School”</strong> (AKA “Detroit School”)</a> maintains that:</p><ul><li>A <strong>unit</strong> is a <strong>unit of behavior</strong>, no matter how big/small</li><li>Each unit test should run in <strong>isolation from all other unit tests</strong></li><li><strong>Test doubles</strong> should <strong>only be used for shared dependencies</strong> (like a database or file system)</li></ul><p>It might already be obvious from my comment above about broadening the definition of “unit” to mean “unit of behavior/work,” but I prefer the Classical School’s perspective on testing. It’s easier to produce tests that are resistant to refactoring by following the Classical School’s paradigm.</p><p>Despite all the disagreements about unit tests, it’s safe to say that everyone agrees that <strong>unit tests prioritize fast feedback</strong>. They’re quick to write, run, and let you know if you broke something.</p><h4 id=integration-tests>Integration Tests<a hidden class=anchor aria-hidden=true href=#integration-tests>#</a></h4><p>Unlike unit tests, <strong>integration tests test more than one unit</strong> <strong>(although not the entire system)</strong>. This means that they tend to take longer to write (and longer to run) than unit tests.</p><p>(Note that, because “unit” is used in this definition as well, the arguments about unit tests bleed over into what counts as an integration test! What the “Classical School” calls unit tests, for example, would often be considered integration tests by the “London School.”)</p><p>What integration tests give up in terms of fast feedback, they gain in terms of <strong>protection against regressions</strong>. That is, they can catch more bugs.</p><p>This is because integration tests exercise more of the codebase than unit tests. They also focus on the interactions between system components, which means that they’re looking for regressions/bugs in areas that are outside of the scope of unit tests.</p><h4 id=end-to-end-or-system-tests>End-to-end or System Tests<a hidden class=anchor aria-hidden=true href=#end-to-end-or-system-tests>#</a></h4><p>Unlike integration tests, end-to-end or system tests <strong>test the entire system</strong>. They take even longer to write and run than integration tests, but they emulate an end-user’s interactions with your system more than any other kind of test.</p><p>System tests <strong>maximize protection against regressions</strong> by exercising the entire code base.</p><p>Using all three different kinds of tests, then, is key to having a test suite that catches bugs and gives fast feedback.</p><p><img alt=UnitTesting04fig12_alt.jpeg loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/3554AE46-C4BA-4C5A-B879-2E6B639AA252_2/qH4ihIUx7NKs4kWQNlU3uNEe2Ji1K3CD0cE8Y1svGI8z/UnitTesting04fig12_alt.jpeg>
(Image source: <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/>Khorikov 2020</a>)</p><h3 id=the-test-pyramid>The Test Pyramid<a hidden class=anchor aria-hidden=true href=#the-test-pyramid>#</a></h3><p>Due to the strengths and weaknesses of the three different kinds of tests, the “test pyramid” model suggests that developers should write many unit tests, fewer integration tests, and even fewer end-to-end tests. The width of the pyramid represents the number of tests at each level.</p><p>Here is Mauricio Aniche’s version of the Test Pyramid, which adds exploratory manual testing (vs. automated testing) as a top layer:</p><p><img alt=EffectiveSoftwareTesting01-08.png loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/AFC5E00F-399B-454E-88E9-96DF37822C93_2/a3yCuLMk35hMVojHrgkpkB9dy9tzOB9RlqBjWHdnCZcz/EffectiveSoftwareTesting01-08.png>
(Image source: <a href=https://learning.oreilly.com/library/view/effective-software-testing/9781633439931/>Aniche 2022</a>)</p><p>The main reason to be <em>sparing</em> in our creation and use of integration and system tests is <strong>time</strong>. Remember, one of the four qualities of a good test is “fast feedback,” and this is definitely a weakness of integration and system tests.</p><p>Nevertheless, because they exercise a lot of the codebase (and thereby increase our code coverage), integration and system tests are particularly good at catching bugs. So, if we want our testing suite to be good at “protection against regressions,” we need to include well-thought-out integration and system tests.</p><h3 id=code-coverage-good-servant-bad-master>Code Coverage: Good Servant, Bad Master<a hidden class=anchor aria-hidden=true href=#code-coverage-good-servant-bad-master>#</a></h3><p>Code coverage is a measurement of <strong>how much of your production code gets executed by your test code.</strong></p><p>On its own, “code coverage” usually refers to “<strong>line coverage</strong>,” meaning the number of lines of code executed by your tests divided by the total lines of code. (If you’ve got 100 lines of code and your tests execute 90 of them, you’ve got 90% code coverage.)</p><p>However, as Aniche (2022) notes, because the complexity of our production code involves more than just the number of lines of code, there are other forms/aspects of code coverage worth considering.</p><ul><li><strong>Branch coverage</strong> takes into account all the <code>true</code> and <code>false</code> branches of the program’s logic (coverage of <code>if(a && b)</code> must test for both <code>a && b == true</code> and <code>a && b == false</code>)</li><li><strong>Condition and branch coverage</strong> builds upon branch coverage to consider each condition that’s a part of a <code>true</code> or <code>false</code> branch (coverage of <code>if(a || b)</code> must test for <code>a == true</code>/<code>b == false</code>, <code>a == false</code>/<code>b == true</code>, and <code>a == false</code>/<code>b == false</code>)</li><li><strong>Path coverage</strong> is the strictest criteria, considering each and every possible path through the program’s logic (coverage of a program with 10 independent <code>true/false</code> conditions would require 2<sup>10</sup> = 1024 test cases)</li></ul><p>In a perfect world, we might always want to shoot for 100% path coverage. But, realistically, achieving full path coverage for complicated production code is far too time-consuming to be valuable.</p><p>Khorikov lists two main problems with code coverage metrics:</p><ul><li><blockquote><p>You can’t guarantee that the test verifies all the possible outcomes of the system under test.</p></blockquote></li><li><blockquote><p>No coverage metric can take into account code paths in external libraries.</p></blockquote></li></ul><p>Regarding the former problem, the combination of implicit and explicit outcomes of the system under test makes it extremely difficult, if not impossible, to test for them all. And, regarding the latter, code coverage metrics do not take the use of external libraries into consideration.</p><p>Does this, then, mean we should not care about code coverage?</p><p>No! But, we should keep in mind that, as Khorikov puts it, “coverage metrics are a good negative indicator, but a bad positive one.”</p><p>This is related to the “absence-of-errors fallacy” mentioned above. That is, if you have very low code coverage, it’s a sure sign that your testing suite has problems. But the mere fact of a high code coverage percentage does not mean that you have a robust testing suite.</p><h3 id=mcdc-coverage>MC/DC Coverage<a hidden class=anchor aria-hidden=true href=#mcdc-coverage>#</a></h3><p>Before we move on from code coverage completely, however, I want to mention what’s known as “modified condition / decision coverage” or “MC/DC” as a way to maximize the value of code coverage while minimizing the number of test cases required.</p><p>As Aniche (2022) summarizes it, MC/DC</p><blockquote><p>“looks at combinations of conditions, as path coverage does. However, instead of testing <em>all</em> possible combinations, we identify the <em>important</em> combinations that need to be tested. MC/DC exercises each of these conditions so that it can, independently of the other conditions, affect the outcome of the entire decision. Every possible condition of each parameter must influence the outcome at least once.”</p></blockquote><p>To achieve MC/DC, you list all possible test cases (those required if you were going for path coverage), before searching for “independence pairs” of test cases where (1) a single condition change (2) independently changes the outcome of the code in question. After finding these independence pairs for all of the conditions, you can reduce the list of test cases down to at least one independence pair for each condition under test.</p><p>If we’re just considering binary true/false conditions, then MC/DC requires N + 1 test cases vs path coverage’s 2<sup>N</sup> test cases (Aniche 2022, citing <a href="https://www.google.com/books/edition/An_Investigation_of_Three_Forms_of_the_M/8ibStgAACAAJ?hl=en">Chilenski 2001</a>).</p><p>While MC/DC isn’t a silver bullet to solve all code coverage issues, it’s a great example of applying the “test the what, not the how” testing principle to the topic of code coverage. When deciding which test cases to (not) write, we want to make sure that we’re covering the aspects of our software’s logic that influence it’s observable behavior.</p><p><img loading=lazy src="https://images.unsplash.com/photo-1503387762-592deb58ef4e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw0fHxibHVlcHJpbnR8ZW58MHx8fHwxNjY1NDkyNjMy&ixlib=rb-1.2.1&q=80&w=1080"></p><h3 id=well-designed-code-is-easy-to-test>Well-Designed Code is Easy to Test<a hidden class=anchor aria-hidden=true href=#well-designed-code-is-easy-to-test>#</a></h3><p>A deep-dive into software design and architecture far exceeds the scope of this overview of software testing principles. Nevertheless, there’s an important connection between software testing and software design.</p><p>Code that is well-designed is easy to test. And code that is difficult to test is often poorly designed.</p><p>When testing is integrated into the software development process, then any friction encountered when writing tests should raise questions about the way the production code is structured. Granted, certain difficulties cannot be avoided (sometimes requirements demand behavior that is inherently difficult to test). But there are often ways to improve the design of our production code while also making it easier to test.</p><h3 id=keep-domain-and-infrastructure-code-separate>Keep Domain and Infrastructure Code Separate<a hidden class=anchor aria-hidden=true href=#keep-domain-and-infrastructure-code-separate>#</a></h3><p>This is the main design principle that Aniche emphasizes in his chapter on “Designing for testability” in <em>Effective Software Testing</em> (2022):</p><blockquote><p>The <em>domain</em> is where the core of the system lies: that is, where all the business rules, logic, entities, services, and similar elements reside. … <em>Infrastructure</em> relates to all code that handles an external dependency: for example, pieces of code that handle database queries (in this case, the database is an external dependency) or web service calls or file reads and writes. In our previous examples, all of our data access objects (DAOs) are part of the <em>infrastructure</em> code.</p><p>In practice, when domain code and infrastructure code are mixed, the system becomes harder to test. You should separate them as much as possible so the infrastructure does not get in the way of testing.”</p></blockquote><p>Keeping domain code (AKA “business logic”) separate from infrastructure code (AKA “application services layer”) is a key emphasis of the “Hexagonal Architecture” or “Ports and Adapters” pattern.</p><p>The business logic at the “center” of your application should only interact with external dependencies by interacting with ports (application services), that interact with adapters, that are themselves coupled to the external dependencies.</p><p><img alt=EffectiveSoftwareTesting07-01.png loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/163B4C46-ECC3-48AF-82E3-92646C4FBD7B_2/OPm3cFAMHapQQOhihmwAaLVGNND3FpEHM0Fw95If49Ez/EffectiveSoftwareTesting07-01.png>
(Image source: <a href=https://learning.oreilly.com/library/view/effective-software-testing/9781633439931/>Aniche 2022</a>)</p><p>This “separation of concerns” approach to software design increases the testability of a system because it allows us to focus our testing efforts, especially at the unit-test level, on the most important part of the system—the domain code—without directly relying on any external dependencies (which could slow our tests down, make them unpredictable, etc.).</p><p>Keeping domain code separate from infrastructure code also helps us to avoid writing brittle tests by emphasizing a key principle behind “resistance to refactoring”—observable behavior vs implementation details.</p><h3 id=observable-behavior-vs-implementation-details>Observable Behavior vs Implementation Details<a hidden class=anchor aria-hidden=true href=#observable-behavior-vs-implementation-details>#</a></h3><p>At each level of a system, there is an important distinction between <strong><em>what</em> the system is accomplishing (the observable behavior)</strong> and <strong><em>how</em> it accomplishes it (implementation details)</strong>.</p><p>At the highest level, <em>inter-system</em> communications between applications are observable behaviors, while <em>intra-system</em> communication between classes inside an application are implementation details.</p><p><img alt=UnitTesting05fig12_alt.jpeg loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/B9F43CB1-DFFA-45E7-9072-18D1BBC56367_2/NBFvJV4sruSIntQaOKcRgfO8WpP7mNWeKI1pmI4eydkz/UnitTesting05fig12_alt.jpeg>
(Image source: <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/>Khorikov 2020</a>)</p><p>Remember that, as we test each level of the system, in order to avoid writing brittle tests that throw false positives, we need to test the observable behavior, and not the implementation details.</p><p>At first glance, it might seem like the distinction is between observable behavior and implementation details is the same as between an applications <strong>public API (application programming interface)</strong> and its <strong>private API</strong>. In languages like C# and Java, this public/private distinction is usually achieved using <strong>access modifiers</strong> (<code>public</code>, <code>private</code>, <code>protected</code>, etc.).</p><p>However, although a <em>well-designed API</em> has a public API that coincides with its observable behavior and a private API that coincides with its implementation details, it’s very easy and common for an application to <strong>“leak” its implementation details into its public API</strong> by making those implementation details inappropriately observable.</p><p>Khorikov highlights the differences here as follows:</p><blockquote><p>“For a piece of code to be part of the system’s observable behavior, it has to do one of the following things:</p></blockquote><ul><li><blockquote><p>Expose an operation that helps the client achieve one of its goals. An <em>operation</em> is a method that performs a calculation or incurs a side effect or both.</p></blockquote></li><li><blockquote><p>Expose a state that helps the client achieve on of its goals. <em>State</em> is the current condition of the system.</p></blockquote></li></ul><blockquote><p>Any code that does neither of these two things is an implementation detail.”</p></blockquote><p>Whenever an application “leaks” its implementation details into its public API, it makes it easy for developers to write brittle tests. As Khorikov observes, “by making all implementation details private, you leave your tests no choice other than to verify the code’s observable behavior, which automatically improves their resistance to refactoring.”</p><h3 id=four-types-of-code-complexitysignificance-vs-number-of-dependencies>Four Types of Code: Complexity/Significance vs Number of Dependencies<a hidden class=anchor aria-hidden=true href=#four-types-of-code-complexitysignificance-vs-number-of-dependencies>#</a></h3><p>In addition to the distinction between observable behavior and implementation details, there’s an important framework to keep in mind when determining how to test each part of our software system.</p><p><img alt=UnitTesting07fig01_alt.jpeg loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/FEB14714-FF80-4C38-A57F-7F190BFF4A40_2/zxxZxZZDo7qDyNjq1Sya4VF9CAK4SnL5jPb7pMnyNmMz/UnitTesting07fig01_alt.jpeg>
(Image source: <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/>Khorikov 2020</a>)</p><p>Khorikov lists the following four types of production code:</p><ul><li><blockquote><p><em>Domain model and algorithms (top left)</em>—Complex code is often part of the domain model but not in 100% of all cases. You might have a complex algorithm that’s not directly related to the problem domain.</p></blockquote></li><li><blockquote><p><em>Trivial code (bottom left)</em>—Examples of such code in C# are parameter-less constructors and one-line properties: they have few (if any) collaborators and exhibit little complexity or domain significance.</p></blockquote></li><li><blockquote><p><em>Controllers (bottom right)</em>—This code doesn’t do complex or business-critical work by itself but coordinates the work of other components like domain classes and external applications.</p></blockquote></li><li><blockquote><p><em>Overcomplicated code (top right)</em>—Such code scores highly on both metrics: it has a lot of collaborators, and it’s also complex or important. An example here are <em>fat controllers</em> (controllers that don’t delegate complex work anywhere and do everything themselves).</p></blockquote></li></ul><p>Although trivial code is difficult, if not impossible, to avoid, well-designed software systems avoid “overcomplicated code” by making sure that code is either complex/significant OR it works with a number of dependencies, but not both at the same time.</p><p>Put differently, the more complicated the code, or the more significant for the domain layer, the fewer collaborators it should have.</p><p>Why? Because, at least from a testing perspective, collaborators are expensive and time-consuming to test. Restricting interaction with collaborators to “controllers” in the application services / infrastructure layer of our application allows us to be strategic in our use of <strong>test doubles and integration tests for the controllers</strong>, while spending more of our valuable time writing <strong>unit tests for our domain code and complex algorithms</strong>.</p><figure>![UnitTesting08fig01_alt.jpeg](https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/D2685F77-D498-4959-9B7D-6FF2DEEAC26A_2/IP8Scjkvxo8Egqj2Fz8ly0vviNmuKTxCKtz97Fyfz5sz/UnitTesting08fig01_alt.jpeg)<figcaption>UnitTesting08fig01\_alt.jpeg</figcaption></figure>(Image source: [Khorikov 2020](https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/))<p>If the classes in our domain code depend only on each other, they should be relatively easy and quick to unit test. Then, after checking as many edge cases as possible in our unit tests, we can judiciously test the happy paths and all other edge cases in our integration tests of the controllers in the application service layer.</p><p>Nevertheless, even if we do all of this properly, we still need to reckon with collaborators and dependencies at some point, ideally without making our testing suite prohibitively expensive and time-consuming to run! This brings us to the important topic of test doubles.</p><p><img loading=lazy src="https://images.unsplash.com/photo-1620889276134-ea33a1084664?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw3NHx8bWFubmVxdWlufGVufDB8fHx8MTY2NTQ5MjczMQ&ixlib=rb-1.2.1&q=80&w=1080"></p><h3 id=test-doubles-mocks-vs-stubs>Test Doubles: Mocks vs Stubs<a hidden class=anchor aria-hidden=true href=#test-doubles-mocks-vs-stubs>#</a></h3><p>Test doubles (think “stunt doubles”) mimic the behavior of dependencies. There are various kinds of test doubles. Aniche (2022) lists five, for example:</p><ul><li>Dummies: passed to the class under test but never used</li><li>Fakes: use simplified implementations of the classes they mimic</li><li>Stubs: provide hard-coded answers to queries (no simplified implementation like fakes)</li><li>Mocks: provide hard-coded answers to queries, recording the interactions that can then be asserted afterward</li><li>Spies: wrap around a real dependency object (not like a mock), recording the interactions (like a mock)</li></ul><p>However, Khorikov (2020) helpfully simplifies this list down to just two kinds of test doubles:</p><ul><li>Mocks (including both mocks and spies)</li><li>Stubs (including dummies, fakes, and stubs)</li></ul><p>What’s the difference between the two? Here’s Khorikov again:</p><ul><li><blockquote><p>Mocks help to emulate and examine <em>outcoming</em> interactions. These interactions are calls the SUT [System Under Test] makes to its dependencies to change their state.</p></blockquote></li><li><blockquote><p>Stubs help to emulate <em>incoming</em> interactions. These interactions are calls the SUT makes to its dependencies to get input data</p></blockquote></li></ul><p>Notice two important things. First, mocks both <em>emulate</em> and <em>examine</em>, while stubs only <em>emulate</em>. Second, mocks mimic interactions that result in <em>side effects</em> or changed state, while stubs mimc interactions that <em>retrieve information</em>. This touches on another important principle: command query separation.</p><h3 id=command-query-separation>Command Query Separation<a hidden class=anchor aria-hidden=true href=#command-query-separation>#</a></h3><p>According to command query separation (CQS), “every method should be either a command or a query, but not both” (Khorikov 2020).</p><ul><li>Commands: produce side effects, but do not return a value</li><li>Queries: return a value, but do not produce side effects</li></ul><p>Another way of summarizing this principle is that “asking a question should not change the answer” (Khorikov 2020).</p><p>Note that, in terms of CQS, mocks mimic commands while stubs mimic queries.</p><p><img alt=Image.tiff loading=lazy src=https://res.craft.do/user/full/032236cd-2bcc-fa12-9dfe-e5564a597e07/doc/836657DD-FF3A-4CE5-8565-F6945FE45D6A/9A23E848-9BAF-4318-8874-FA36C3D793F6_2/x5OUyH6SgUYVQnLrLvyE0Bya9z3mvCQcJrtuH90Ndxsz/Image.tiff>
(Image source: <a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/>Khorikov 2020</a>)</p><h3 id=when-to-use-mocks-and-stubs>When to Use Mocks and Stubs<a hidden class=anchor aria-hidden=true href=#when-to-use-mocks-and-stubs>#</a></h3><p>A corollary of what we’ve just discussed is that we should <strong>never assert (verify) interactions with stubs in our tests</strong>. Doing so is unnecessary if our tests are correctly focusing on observable behavior, because stubs should only ever emulate steps on the way to our SUT (system under test) producing observable output.</p><p>A corollary of what we previously discussed about complexity/significance vs number of collaborators means that <strong>we should not have to use test doubles in our unit tests of domain code (and complex algorithms), but should rather save mocks and stubs for our integration tests of controllers and application services code</strong>.</p><p>Put differently: save test doubles for the outside “edges” of your system, where you need to verify interactions with dependencies that you don’t have control over.</p><p>When unit testing domain code classes at the “center” of your system, the only direct dependencies should be upon other domain code classes. And, since we’ve already discussed the benefit of expanding our definition of “unit” beyond “class” to include “unit of behavior/work,” <strong>we should use real versions of these “in-process” dependencies in our unit tests, instead of replacing them with mocks or stubs</strong>.</p><p>And, even when writing integration tests for application service code, when interactions with “out-of-process” dependencies are inescapable, <strong>we should only replace unmanaged out-of-process dependencies with test doubles. Whenever possible, we should use real instances of managed out-of-process dependencies (such as a database) in our integration tests, rather than replacing these with mocks or stubs</strong>.</p><p>Finally, when replacing unmanaged dependencies with test doubles, we should do so by creating (and then mocking or stubbing) an adapter layer that stands between our application and the third-party dependency. In other words, even when mocking a dependency you don’t control, you should “only mock types that you own” (Khorikov 2020). This doesn’t mean that you should mock managed dependencies like your database (see above)! But it does add in a helpful buffer between your application and its unmanaged dependencies.</p><p><img loading=lazy src="https://images.unsplash.com/photo-1471958680802-1345a694ba6d?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw2fHxyb2FkfGVufDB8fHx8MTY2NTQ5MjQ3Mw&ixlib=rb-1.2.1&q=80&w=1080"></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Much more could be (and has been) said about software testing! If I had more time, I would discuss the following. But I recommend that curious readers do their own research on:</p><ul><li><a href=https://www.baeldung.com/parameterized-tests-junit-5>Parameterized testing</a>, which can help save time and space when you’ve got a bunch of test cases you need to cover for a single method</li><li><a href=https://medium.com/criteo-engineering/introduction-to-property-based-testing-f5236229d237>Property-based testing</a>, which leverages software to create and handle test cases given pre-defined “properties” or parameters that should be followed when generating possible inputs for your tests</li><li><a href=https://en.wikipedia.org/wiki/Mutation_testing>Mutation testing</a>, which makes dynamic changes (“mutants”!) to your production code, and then sees whether or not those changes cause a test to fail (if, say, changing an <code>if (A)</code> to <code>if (!A)</code> causes a test to fail, then you’ve “killed” the mutant; if changing the logic of your program doesn’t cause any tests to fail, then the mutant has “survived”)</li></ul><p>…Not to mention doing your own research on testing libraries and frameworks in your favorite language(s)! (In Java world, that includes <a href=https://junit.org/junit5/>JUnit</a>, <a href=https://site.mockito.org/>Mockito</a>, <a href=https://jqwik.net/>jqwik</a>, <a href=https://assertj.github.io/doc/>AssertJ</a>, <a href=https://pitest.org/>Pitest</a>, etc.)</p><p>Nevertheless, I hope that this overview of software testing possibilities, problems, and principles helps you to write better tests and develop better software! If you have anything to add or correct, please do leave a comment. Or reach out to me (Twitter <a href=https://twitter.com/joshuapsteele>@joshuapsteele</a>, GitHub <a href=https://github.com/jsteelepfpt>jsteelepfpt</a>, LinkedIn <a href=https://www.linkedin.com/in/joshuapsteele/>joshuapsteele</a>).</p><hr><p><img loading=lazy src="https://images.unsplash.com/photo-1600431521340-491eca880813?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxNDIyNzR8MHwxfHNlYXJjaHw2fHxsaWJyYXJ5fGVufDB8fHx8MTY2NTQ5MjQzNA&ixlib=rb-1.2.1&q=80&w=1080"></p><h2 id=recommended-resources-on-software-testing>Recommended Resources on Software Testing<a hidden class=anchor aria-hidden=true href=#recommended-resources-on-software-testing>#</a></h2><ul><li>Test Case Checklist in <a href=https://learning.oreilly.com/library/view/code-complete-2nd/0735619670/><em>Code Complete</em></a>, 2nd edition by Steve McConnell (Microsoft 2004:532)</li><li><a href=https://learning.oreilly.com/library/view/effective-software-testing/9781633439931/><em>Effective Software Testing: A Developer’s Guide</em></a> by Mauricio Aniche (Manning, 2022)</li><li><a href=https://learning.oreilly.com/library/view/full-stack-testing/9781098108120/><em>Full Stack Testing: A Practical Guide for Delivering High Quality Software</em></a> by Gayathri Mohan (O’Reilly, 2022)</li><li><a href=https://learning.oreilly.com/library/view/unit-testing-principles/9781617296277/><em>Unit Testing Principles, Practices, and Patterns</em></a> by Vladimir Khorikov (Manning, 2020)</li><li>“<a href=https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/f_0065.xhtml>Topic 41: Test to Code</a>” and “<a href=https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/f_0066.xhtml>Topic 42: Property-Based Testing</a>” in <a href=https://learning.oreilly.com/library/view/the-pragmatic-programmer/9780135956977/><em>The Pragmatic Programmer: Your Journey to Mastery</em></a> by David Thomas and Andrew Hunt (2nd Edition; Addison-Wesley Professional, 2019)</li><li>“<a href=https://martinfowler.com/articles/microservice-testing/>Testing Strategies in a Microservice Architecture</a>” by Toby Clemson (Slide Deck)</li><li>“<a href=https://profinit.eu/wp-content/uploads/2016/03/HardSwTesting.pdf>What Is Software Testing? And Why Is It So Hard?</a>” by James A. Whittaker (IEEE Software, January 2000:70–79)</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://joshuapsteele.com/tags/software/>Software</a></li><li><a href=https://joshuapsteele.com/tags/testing/>Testing</a></li></ul></div><nav class=paginav><a class=prev href=https://joshuapsteele.com/logos-10-bible-software-the-ultimate-theological-learning-tool/><span class=title>« Prev</span><br><span>Logos 10 Bible Software: The Ultimate Theological Learning Tool</span>
</a><a class=next href=https://joshuapsteele.com/chatgpt-write-a-viral-blogpost-about-why-to-become-a-software-engineer/><span class=title>Next »</span><br><span>ChatGPT: Write a Viral Blogpost about Why to Become a Software Engineer</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on x" href="https://x.com/intent/tweet/?text=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles&amp;url=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f&amp;hashtags=software%2ctesting"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f&amp;title=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles&amp;summary=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles&amp;source=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f&title=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on whatsapp" href="https://api.whatsapp.com/send?text=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles%20-%20https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on telegram" href="https://telegram.me/share/url?text=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles&amp;url=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Software Testing: Possibilities, Problems, and Principles on ycombinator" href="https://news.ycombinator.com/submitlink?t=Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles&u=https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div class=lets-talk-section><hr><h2>Let's Talk</h2><div class=post-reply-buttons><a href="mailto:blog@joshuapsteele.com?subject=Re: Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles" class=reply-button>📧 Reply via email
</a><a href="https://bsky.app/intent/compose?text=%40joshuapsteele.bsky.social+Re%3A+Software+Testing%3A+Possibilities%2C+Problems%2C+and+Principles+https%3A%2F%2Fjoshuapsteele.com%2Fsoftware-testing-possibilities-problems-and-principles%2F" class=reply-button>🦋 Reply via Bluesky
</a><a href="https://micro.blog/post?text=@joshuapsteele Re: Software%20Testing%3a%20Possibilities%2c%20Problems%2c%20and%20Principles https%3a%2f%2fjoshuapsteele.com%2fsoftware-testing-possibilities-problems-and-principles%2f" class=reply-button>🌐 Reply via Micro.blog</a></div><hr></div></article></main><script src=https://tinylytics.app/embed/kLx6jW19SrdcVTjNny3p.js?hits&countries&kudos defer></script><footer class=footer><span>&copy; 2025 <a href=https://joshuapsteele.com/>Joshua P. Steele</a></span><br>Navigate my <a href=/blog>blog</a> by <a href=/categories>categories</a> and <a href=/tags>tags</a><br><span>Find me on
<a href=https://social.joshuapsteele.com/ target=_blank>micro.blog</a> &
        <a href=https://steele.omg.lol/ target=_blank>omg.lol</a></span><br><span><span class=tinylytics_hits></span> visits from the following countries:</span><br><span class=tinylytics_countries></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>